%************************************************
\chapter{General Discussion and Conclusions}\label{ch:discusion}
%************************************************
\section{General Discussion}
The different contributions that make up this thesis have already been discussed in detail at each chapter. However, in this last chapter, we will discuss the contributions that this work makes to neuroimaging and the \ac{CAD} field itself, and what discoveries (or confirmations) we have done on the different diseases that have been analysed. 

\subsection{Discussion on the algorithms}
As commented at the introduction, in this thesis we proposed different strategies for tackling the small sample size problem. The first three approaches (chapters~\ref{ch:decomposition}, \ref{ch:texture} and \ref{ch:sbm}) are feature extraction algorithms that perform a significant reduction of the number of features used in neuroimaging. 

% Decomposition 
In the decomposition approach (chapter~\ref{ch:decomposition}), we obtained a very significant feature reduction, from hundreds of thousands of voxels to between 2 and 25 features, which were the coordinates of each sample in the space defined by the components. Both \ac{FA} and \ac{ICA} were able to detect similar regions in the \ac{AD} and \ac{PKS} functional datasets, obtaining an accuracy higher than 90\% in the first and higher than 95\% in the latter. 

The decomposition also makes our \ac{CAD} better generalizable, since the features are no longer subject to the small sample size problem (the number of subjects is several times higher than the number of features). The samples are projected to a dense space, where the \ac{SVC} are able to perform a reliable classification, and it also implies a more accurate model of the diseases studied. 

Thanks to the softness of nuclear imaging techniques such as \ac{PET} and \ac{SPECT}, the decomposition techniques are a very useful tool to characterize and predict the stage of a disease. However, due to their resolution, they could not perform as well in structural \ac{MRI} datasets unless they have been previously smoothed. 

% Texture
As for the texture-based \ac{CAD} proposed in Chapter~\ref{ch:texture}, we have already seen its potential when applied to DaTSCAN images. In these images, the cluster tendency and homogeneity were the texture features that achieved best performance, which is closely related to the characteristics of the images. Since the distribution of intensities is highly concentrated around the striatum, differences in shape (cluster tendency) and in the distribution of the radiopharmaceutical (homogeneity) are usually regarded by physicians when working with this modality. A combination of these and other texture features yielded the best outcome, achieving up to 97\% accuracy in the PPMI-DAT dataset (excluding \ac{SWEDD} subjects) -COMPROBAR-, when using the relative entropy (or \ac{KL} divergence) as selection criterion. 

Despite their ability in detecting \ac{PD} related \ac{DAT} deficit in DaTSCAN imaging, these texture features are an inviting possibility to explore in conjunction with other modalities such as \ac{MRI}. In structural images, textural information in high resolution is available, which could be exploited to characterize textural changes in longitudinal datasets, and associate these with the progression of neurodegeneration. 

% SBM
Finally, we have proposed \ac{SBM} in Chapter~\ref{ch:sbm}, a novel technique that maps structural (and possibly functional) images to two-dimensional maps representing various measures. The \ac{SBM} establishes a framework that has been expanded witch divisions on the mapping vector, extensions to the type of sampling and even a path tracing algorithm based on \ac{HMM}. Of these, the most powerful approaches were the original \ac{SBM} measures (specifically, the average of the the intensities selected by the mapping vector) and the \ac{VRLBP} approach, that characterized the texture of and around the mapping vector by means of an helical sampling. The \ac{HMM} paths, for their part, were not as powerful as a feature selection algorithm, although their ability to adapt to the intensity changes on the images make them a perfect candidate for testing new possibilities such as morphological measures, or even image segmentation. 

The whole \ac{SBM} framework is still to be developed, but it shows very promising results in the classification of structural images. In some preliminary results that we are currently testing, the application of \ac{SBM} to predict the conversion of \ac{MCI} to dementia versus \ac{MCI} stable has reached the nondescript amount of 77.6\% accuracy. The \ac{MCI} conversion is today a major challenge, and results like these open a whole range of possibilities. 

% SWPCA
On the other hand, chapters~\ref{ch:swpca} and \ref{ch:simulation} aimed at increasing the number of samples available, and solve problems that usually appear when working with large datasets. The \ac{SWPCA} (Chapter~\ref{ch:swpca}), developed by the PhD candidate at the University of Cambridge, was intended to correct many inhomogeneities that have been identified in multicentre datasets like the \aimsmri{}. These inhomogeneities caused a \ac{SVC} to be able to distinguish between centres with higher accuracy than between subjects affected by \ac{ASD}. Our intention was to correct this behaviour by decomposing the images using \ac{PCA} and parsing out the components whose contribution was more related to the acquisition site. After applying \ac{SWPCA} to the dataset we found that many recent claims about \ac{ASD} heterogeneity \cite{haar2014anatomical} were well founded, given that the differences between individuals affected and not-affected by the disorder were almost null. This makes it a very useful tool for merging structural dataset acquired at different centres, with the reported limitation that it needs a large sample size at each centre to work out these site differences. 

% Synthesis. 
Finally, the functional brain synthesis algorithm proposed in Chapter~\ref{ch:simulation} offers an inviting possibility to every neuroimaging scientist: generate hundreds of new images that share characteristics with a certain datasets. It only needs a large enough dataset (of hundreds of images) that has been previously normalized in both space and intensity. Our algorithm transform the original dataset to the `eigenbrain' space, where the statistical distribution of each class is estimated, and then, new coordinates of these can be generated. The synthesized images closely resemble the original ones, and physicians were unable to realize which one was real and which one synthesized in a preliminary test. The experiments proposed in that chapter prove that the synthesized images can effectively predict real world examples and, at the same time, be independent from the original ones. A \ac{SPM} analysis revealed that the significant class differences are in the same location in both original and simulated images. 

We have proved the ability of all these algorithms in the differential diagnosis of two diseases, \ac{AD} and \ac{PD}, and the utility of the \ac{SWPCA} to reduce the site-related inhomogeneities in multicentre datasets. All these algorithms perform either a reduction of the feature space or a safe increase of the sample size in order to reduce the amount of false positives currently found in neuroimaging studies. Other improvements, such as the computational load reduction thanks to feature extraction or the \ac{SBM} visualization tools may also be acknowledged. 


\subsection{Discussion on the Disorders}
All the aforementioned \ac{CAD} tools have been applied to different neuroimaging datasets that comprise \ac{AD} (chapters~\ref{ch:decomposition}, \ref{ch:sbm} and \ref{ch:simulation}), \ac{PKS} (chapters~\ref{ch:decomposition}, \ref{ch:texture} and \ref{ch:simulation}) and \ac{ASD} (chapter~\ref{ch:swpca}). Several structural (chapters~\ref{ch:sbm} and \ref{ch:swpca}) and functional (chapter~\ref{ch:decomposition}, \ref{ch:texture} and \ref{ch:simulation}) have been used to analyse these neurological and psychiatric disorders as well. 

% AD
Regarding \ac{AD}, we found consistent hypometabolism and hypoperfusion patterns, using the \adnipet{} and \vdlnhmpao{} datasets. In chapter~\ref{ch:decomposition} we reported general patterns that could be found in both modalities, mainly at the occipital and temporal lobes, with strong focus on the angular gyrus \cite{Dubois2007,Claus1994}. These patterns were afterwards confirmed at ch.~\ref{ch:simulation}. 

Appart from these common regions, the most relevant differences in the \adnipet{} dataset were located at the angular gyrus and the cingulum, although fundamental structures linked to \ac{AD} such as the hippocampus or the parahippocampal gyrus were also highlighted by some of the selection criteria \cite{Stoeckel04,Illan2011}. However, when using the \vdlnhmpao{}, the selected regions were more diffuse (probably due to less resolution images), and mainly located at the angular gyrus, the occipital lobe and parts of the temporal lobe \cite{Dubois2007,Claus1994}. When using these selection criteria (and consequently, the intensity of these regions), our system achieved the best performance, which gives us an idea of the most relevant differences between \ac{AD} and \ac{CTL} in functional datasets. 

\ac{AD} was also analysed at chapter~\ref{ch:sbm}, by means of the \ac{SBM} of \ac{MRI} datasets. We already mentioned the best performing measures: the average and the \ac{VRLBP}, which may be linked to anatomical properties such as tissue density and texture. When overimposing the reference image to the \ac{SBM} $t$-maps over the average measure, fundamental differences were found at the middle temporal lobe, amygdala, hippocampus, parahippocampal gyrus or some structures of the basal ganglia, such as caudate nucleus, globus pallidus or putamen \cite{Dubois2007,Pievani2013}. The best performing \ac{VRLBP} approach, however, was more precise, and focused mainly on small areas at the temporal lobe, and the space between the amygdala and hippocampus. It was in these parts where most of the texture changes were detected, and its higher performance gives a hint about the relevance of this report. 

A more complex study of the \ac{MCI} progression is currently being performed using \ac{SBM} analysis of a longitudinal \ac{ADNI} dataset, and the preliminary results are very promising. However, there is still much to be done, and we cannot still report significant differences that allow us to predict \ac{MCI} conversion at the moment. 

% PKS
Now, we will focus on the analysis of \ac{PKS}. In this thesis, we have always use \ac{SPECT}-DaTSCAN imaging, and the reported differences correspond only to this. Since DaTSCAN is a highly specific drug that binds to the \acs{DAT} at the striatum, we can easily observe dopaminergic deficit due to neurodegeneration in \ac{PD}, and distinguish this from other extrapyramidal symptoms. 

In chapter~\ref{ch:decomposition} we performed the analysis of the three DaTSCAN datasets: \ppmidat{}, \vdlndat{} and \vdlvdat{}. Although they yielded differing performance (mainly due to the inclusion or not of \ac{SWEDD} subjects in the analysis of chapter~\ref{ch:decomposition} and but never at chapter~\ref{ch:texture}), the affected regions were obviously located at the main \ac{ROI}. The voxels selected by different criteria were located in areas covering the whole caudate, putamen and globus pallidus, but also, in the case of $t$-test or wilcoxon, some external structures. The relative entropy, however, focused only on the striatum, and achieved the best performance, from which we can conclude that all the other areas introduced mostly noise.

The texture analysis of chapter~\ref{ch:texture} was more focused on the differences between dopaminergic deficit caused by \ac{PD}, and therefore, we excluded \ac{SWEDD} subjects from the analysis. The texture analysis, especially using texture measures such as cluster tendency and homogeneity, achieved remarkably high accuracy in all three \ac{PKS} datasets, which correspond to abnormalities in the shape and intensity of the striatum, along with bilateral differences. These patterns have been widely reported in the literature \cite{Towey2011,Illan2012,martinez2014parametrization} and were confirmed as well in the \ac{SPM} analysis of both the original and synthesized datasets at chapter~\ref{ch:simulation}. 

% ASD
Finally, the analysis of the \aimsmri{} dataset gave us first an idea of the problems to which multi-centre datasets are subject to. The differences between acquisition site were far more significant than the differences between \ac{ASD} affected subjects and \ac{CTL}. That helped us to devise the \ac{SWPCA} method, which, once it had reduced the influence of the acquisition site on the images, yielded a surprising result: that either there was no difference between classes, or these differences were so heterogeneous that the analysis could not establish any common patterns. Patterns reported in other works could be probably linked to the dataset used and these acquisition site effects, as it had been anticipated by a groundbreaking paper in 2014 \cite{haar2014anatomical}. We proposed that defining meaningful subgroups based on different measures, such as genetic profiling, clinical co-morbidities or sensory sensitivities, is the most urgent next step for \ac{ASD} research, in contrast to the recent pooling of \ac{ASD} and other disorders such as Asperger's Syndrome in the same category of the DSM-V manual \cite{Association2013}. 

%\section{Future Work}

\section{Conclusions}


All these algorithms and frameworks are indeed complementary. One can use the synthesis algorithm to double the size of an existing dataset, and then use decomposition to reduce the feature space. Or purge a multi-centre database with \ac{SWPCA} and then analyse and visualize the differences using \ac{SBM}. These are only recent contributions to the neuroimage processing 

