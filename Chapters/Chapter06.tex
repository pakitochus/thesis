%************************************************
\chapter{Spherical Brain Mapping}\label{ch:sbm}
%************************************************
\section{Introduction}
In this section we will present a feature extraction technique called \acf{SBM}. \ac{SBM} is based on the use of spherical coordinates to extract radial features from structural \ac{MRI} images. Using the features at each coordinate, we can characterize the texture in each direction, and even project the information to a bidimensional maps, which provides a significant feature reduction and a visual aid for diagnosis. 

The most basic form is the standard \ac{SBM} \cite{Martinez-Murcia2014225,Martinez-Murcia2015}, in which all voxels crossed by a rectilinear vector in a spherical coordinate pair ($\theta,\varphi$) are selected, and then, a certain measure is extracted from that set. In this sense, statistical and morphological measures such as tissue thickness, average or entropy, among others, are computed. 

Further improvements can be made to this simple approach, for example, with the layering extension \cite{Martinez-Murcia2015}, in which the mapping vector is divided in $n$ subsets containing the same number of voxels. Therefore, instead of a single map, we can obtain $n$ maps at different distances from the centre of the brain. Another useful approach is the characterization of texture features via \acf{LBP}, computed around the mapping vector, which yielded very good results in \cite{Martinez-MurciaVRLBP}.

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.8\textwidth]{Graphics/ch6/01-flowdiagram}
	\caption{Flow diagram of the procedure used in the textural analysis of projected MR brain images.}
	\label{fig:flowdiagram}
\end{figure*}

The most relevant extension to the \ac{SBM} was proposed in \cite{Martinez-Murcia2016}. In this work, instead of using rectilinear vectors to select voxels, we developed a path creation algorithm that follows a minimum-intensity change path towards an attractor placed in its corresponding spherical coordinate pair ($\theta,\varphi$). This way, the mapping paths follow the structural features of the \ac{MRI} image, which could be used to create the bidimensional \ac{SBM} maps as well as directly use the intensity distribution along the path. This was extended to make use of the \ac{GLCM} and Haralick texture analysis (see Chapter~\ref{ch:texture}) to characterize the brain texture along each path and its neighbourhood. 


\section{Spherical Brain Mapping}\label{sec:mapping}
The original \ac{SBM} proposed in \cite{Martinez-Murcia2014225,Martinez-Murcia2015} was based on the use of spherical coordinates in the brain. The central voxel is used as the origin point from which a number of mapping vectors $\mathbf{v}_{\theta,\varphi}$ are defined for each inclination ($\theta$) and azimuth ($\varphi$) angles in the range $0^{\circ}<\theta<180^{\circ}$ and $0^{\circ}<\varphi<360^{\circ}$ (see Figure~\ref{fig:brainmapping}). The voxels crossed by this mapping vector are selected, to form the sampled set $V_{\theta,\varphi}$, a set that contains $P$ voxels crossed by the mapping vector $\mathbf{v}_{\theta,\varphi}$.

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\columnwidth]{Graphics/ch6/02-projection}
	\caption{Illustration of the computation of the mapping vector $\mathbf{v}_{\theta,\varphi}$, the angles $\theta$ and $\varphi$ and the $r$-neighbourhood of $\mathbf{v}$ (see Section~\ref{sec:vrlbp}).}
	\label{fig:brainmapping}
\end{figure}

The basic form in which \ac{SBM} works is by computing a mapping value $v$ from each set $V_{\theta,\varphi}$ at each coordinate pair $(\theta,\varphi)$. In \cite{Martinez-Murcia2014225,Martinez-Murcia2015}, six basic measures were proposed: 


\begin{itemize}
	\item A basic \underline{brain surface} approach, which is intended to characterize the surface of either \ac{GM} or \ac{WM} tissue. It accounts for the distance between the origin and the last tissue voxel in $V_{\theta,\varphi}$ greater than a threshold $I_{th}$. This might correlate with structural neurodegeneration and tissue loss in the surface of the tissue. 
	\begin{equation}\label{eq:surface}
	v_{surf}= \argmax_i \lbrace V_{\theta,\varphi}(i)>I_{th}\rbrace \quad \forall i=1,\dots P
	\end{equation}  
	
	\item The \underline{thickness} of the tissue. It is defined as the distance between the last and first elements in $V_{\theta,\varphi}$
	with an intensity greater than a threshold $I_{th}$ (typically 0). This can be useful when measuring the thickness of segmented \ac{GM} or \ac{WM} maps, and, although less powerful than other implementations like Freesurfer's \cite{Dale1999}, it might be representative enough and easier to compute : 
	\begin{equation}\label{eq:thickness}
	v_{thick}=\argmax_i \lbrace V_{\theta,\varphi}(i)>I_{th}\rbrace- \argmin_i \lbrace V_{\theta,\varphi}(i)>I_{th}\rbrace
	\quad \forall i=1,\dots P
	\end{equation}  
	
	\item The \underline{number of folds} represents the number of overlapping segments of tissue in the set $V_{\theta,\varphi}$. It is computed by counting the number of connected subsets in a thresholded $V_{\theta,\varphi}$ using the value $I_{th}$. Let $A_{\theta,\varphi}$ be the set that contains all the indices of the voxels in $V_{\theta,\varphi}$ with an intensity greater than $I_{th}$:
	\begin{equation}
	A_{\theta,\varphi} = \lbrace i \; / \: V_{\theta,\varphi}(i)>I_{th} \rbrace
	\end{equation}
	where $A_{\theta,\varphi} \in \mathbb{N}$. Let us divide $A_{\theta,\varphi}$ in $J$ disjoint connected subsets so that:
	\begin{equation}
	A_{\theta,\varphi} = A_{\theta,\varphi}^1 \cup A_{\theta,\varphi}^2 \cup \dots \cup A_{\theta,\varphi}^J \quad \text{so that} \quad A_{\theta,\varphi}^i \cap A_{\theta,\varphi}^j = \emptyset \quad \forall i,j
	\end{equation}
	Therefore, our $v_{nf}=J$, the number of disjoint connected subsets in $A_{\theta,\varphi}$.
	
	\item The \underline{average} of $V_{\theta,\varphi}$: 
	\begin{equation}\label{eq:mean}
	v_{av}=\frac{1}{N}\sum_i V_{\theta,\varphi}(i) \quad \forall i=1,\dots P
	\end{equation}  
	
	\item The \underline{entropy} of $V_{\theta,\varphi}$, assuming it is a probability mass vector (probability of belonging to a certain tissue, normalized). It computes $v$ as:
	\begin{equation}
	v_{ent}=\sum_i V_{\theta,\varphi}(i)*\log(V_{\theta,\varphi}(i)) \quad \forall i \in \arg_i\lbrace V_{\theta,\varphi}(i)>0\rbrace
	\end{equation}
	
	\item The uncorrected \underline{kurtosis}, also known as fourth standardized moment, of the set $V_{\theta,\varphi}$ in which $v$ is calculated using:
	\begin{equation}
	v_{kurt}= \frac{\frac{1}{N}\sum_i\left(V_{\theta,\varphi}(i)-\bar{V}_{\theta,\varphi}(i)\right)^4}{\left(\frac{1}{N}\sum_i\left(V_{\theta,\varphi(i)}-\bar{V}_{\theta,\varphi}(i)\right)^2\right)^2} \quad \forall i=1,\dots P
	\end{equation}
	where $\bar{V}_{\theta,\varphi}$ is the average of all voxels in $V_{\theta,\varphi}$ (same value as $v_{av}$, described in Eq.~\ref{eq:mean}). 
	
\end{itemize}

We can compute each of these six maps over the \ac{GM} or \ac{WM} tissue maps of a segmented \ac{MRI}, which are depicted in Figure~\ref{fig:masksGM}. In these maps, the value $v$ computed at each direction $(\theta,\varphi)$ is represented, where the azimuth $\varphi$ is represented in the x-axis, from $0^{\circ}$ to $360^{\circ}$ and the inclination angle $\theta$ in the y-axis, from $0^{\circ}$ to $180^{\circ}$. The whole algorithm that produces these maps can be downloaded at \url{http://pakitochus.github.io/mapBrain/}.

\begin{figure*}[htp]
	\centering
	\includegraphics[width=1\textwidth]{Graphics/ch6/03-projections}
	\caption{Resulting \acs{GM} and \acs{WM} maps of the same control subject using the six proposed measures: Surface, Thickness, Number of Folds, Average, Entropy and Kurtosis.}
	\label{fig:masksGM}
\end{figure*}

This methodology defines the sampling set as the voxels that are crossed by the sampling vector $\mathbf{v}_{\theta,\varphi}$. This implies a loss of information on the neighbourhood of $\mathbf{v}_{\theta,\varphi}$ that increases with the distance to the origin. To overcome this problem, two different approaches have been suggested. In the first one, the sampled set $V_{\theta,\varphi}$ is divided in $n$ equal parts, and one map is computed for each of the $n$ parts, in the ``Layered approach''. A second approach uses \acf{LBP} and helical sampling to map the neighbourhood of $\mathbf{v}_{\theta,\varphi}$ and characterize texture. Finally, we will define new paths that adapt to the intensity changes of the brain images, using a \ac{HMM} based approach. 

\subsection{Layered Extension}\label{sec:layered}
The layered extension is the simplest approach to keep relevant information of the different ``layers'' of tissue in our \ac{SBM} maps. To do so, we divide each sampled set $V_{\theta,\varphi}$ in $n$ equal subsets, from which $n$ maps will be derived. For example, with a $n=4$, 4 subsets will be used to compute 4 different maps at different distances from the origin, from the closest to the farthest. We assume that this approach features more detail, since overlapping structures placed at different depths will be contained within different maps. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/layeredAverageGM}
	\caption[Example of the layered approach using the average measure on \acs{GM} maps.]{Example of the layered approach using the average measure on \ac{GM} maps. Some internal \ac{GM} structures such as the Putamen or Globus Pallidus can be identified at Layer 2 (see anatomical reference at Figures~\ref{fig:regionsCort} and \ref{fig:regionsSub}).}
	\label{fig:layeredGM}
\end{figure*}

\subsection{Volumetric Radial LBP}\label{sec:vrlbp}
Another addition that can be made to the original \ac{SBM} is the inclusion of the $r$-neighbourhood of the mapping vector $\mathbf{v}_{\theta,\varphi}$ in the computation of $v$. We do so by computing the \acf{VRLBP}, based on the \ac{LBP} descriptors proposed in \cite{Ojala1996}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.8\textwidth]{Graphics/ch6/lbpLinear}
	\caption{Example of how the basic \acs{LBP} is computed.}
	\label{fig:lbpBasic}
\end{figure*}

\ac{LBP} was devised to describe the texture of a image, with an initial application to face recognition. In its basic form, it consist of three steps: sampling, calculating the difference and thresholding (See Figure~\ref{fig:lbpBasic}). The value of the \ac{LBP} is defined as:
\begin{equation}
v_{LBP} = \sum_{p=0}^{P-1} s(I_p - I_c)2^p
\end{equation}
where $P$ is the number of neighbours at a distance $r$ of the central voxel, and $I_p$ and $I_c$ are the intensities of the $p^{th}$ voxel and the central voxel for which the value $v_{LBP}$ is being computed. The threshold step is performed using the sign function $s(x)$, defined as:
\begin{equation} % He simplificado la formula usando "cases"
s(x) = 
\begin{cases}
1      &  x \geq 0 \\
0      &  x < 0
\end{cases}
\end{equation}

This basic approach was extended to Volumetric \ac{LBP} \cite{Zhao2007}, in which a 3D texture is defined in a local neighbourhood using a cylinder of radius $r$ oriented in one direction. For this work, we will update the sampling procedure proposed in \cite{Zhao2007} using a helix around the mapping vector $\mathbf{v}_{\theta,\varphi}$ (see Figure~\ref{fig:brainmapping}). This new helical sampling of \cite{Martinez-MurciaVRLBP} defines the set of $P$ sampled voxels on the image $I$ using a $r$-neighbourhood $V_{\theta,\varphi}^{P,r}$ as:

\begin{equation}
V_{\theta,\varphi}^{P,r}=\lbrace I(\mathbf{g}_{\theta,\varphi}^{0,r}), I(\mathbf{g}_{\theta,\varphi}^{1,r}), I(\mathbf{g}_{\theta,\varphi}^{2,r}), \dots I(\mathbf{g}_{\theta,\varphi}^{P-1,r})\rbrace
\end{equation} 
where the coordinate vector $\mathbf{g}_{\theta,\varphi}^{p,r}$ of each voxel are computed in the direction of $\mathbf{v}_{\theta,\varphi}$ by: 
\begin{equation}
\label{ec:helical_coordinates}
\mathbf{g}_{\theta,\varphi}^{p,r}=\begin{cases}
x_{\theta,\varphi}^{p,r}=p\sin(\varphi)\cos(\theta)-r\sin(2\pi np/P)\\
y_{\theta,\varphi}^{p,r}=p\sin(\varphi)\sin(\theta)+r\cos(2\pi np/P)\\
z_{\theta,\varphi}^{p,r}=p\cos(\varphi) 
\end{cases} \quad p=\{0,...,P-1\}, P \in \mathbb{N}
\end{equation}
being $n$ the number of turns in the helical sampling. We use linear interpolation to estimate the intensities in positions that do not fall exactly at the coordinates computed in Eq.~\ref{ec:helical_coordinates}, as in \cite{Zhao2007}. 

If we fix $P$ and $r$ to constant values, the set of sampled voxels $V_{\theta,\varphi}^{P,r}$ becomes $V_{\theta,\varphi}$, which is similar to the definition of \ac{SBM} found in Section~\ref{sec:mapping}. The value $v$ of the \ac{VRLBP} approach is therefore defined as: 
\begin{equation}
v_{VRLBP} = \sum_{p} s(V_{\theta,\varphi}(p)-V_{\theta,\varphi}(0))\cdot 2^{p} \quad \forall p=1,\dots P
\end{equation}

The resulting texture maps for \ac{GM} and \ac{WM} tissues can be found at Figure~\ref{fig:vrlbp}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=\textwidth]{Graphics/ch6/04-vrlbp}
	\caption{An example of the \acs{VRLBP} projection for \acs{GM} and \acs{WM} Tissues. }
	\label{fig:vrlbp}
\end{figure*}

%\lstset{language=python} 
%\begin{lstlisting}
%	def foo():
%		hola amigo
%		print('amigo')
%	
%	eh = foo("amigo")
%	
%	string title = "This is a Unicode $\pi$ in the sky"
%	/*
%	Defined as $\pi=\lim_{n\to\infty}\frac{P_n}{d}$ where $P$ is the perimeter
%	of an $n$-sided regular polygon circumscribing a
%	circle of diameter $d$.
%	*/
%	const double pi = 3.1415926535
%\end{lstlisting}

\subsection{Anatomical Reference}\label{sec:anatomical}
To better understand the \ac{SBM} maps, and the location of different features, we have projected the widely known \cite{AAL} atlas \cite{Tzourio-Mazoyer2002} using \ac{SBM}. That way, we have an anatomical reference of the different structures and their position in the different coordinate pairs $(\theta,\varphi)$. The regions are displayed in  Figures~\ref{fig:regionsCort} and \ref{fig:regionsSub}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{Graphics/ch6/05-regions_cortical}
	
	\caption[SBM mapping of different cortical regions.]{\ac{SBM} mapping of different cortical regions. In the Frontal region, we can find: 1) Frontal Sup., 2) Frontal Mid., 3) Frontal Inf. Oper., 4) Frontal Inf. Tri., 5) Frontal Sup. Orb, 6) Frontal Mid. Orb, 7) Frontal Inf. Orb, 8) Frontal Sup. Medial, 9) Rectus, 10) Frontal Med. Orb., 11) Precentral, 12) Supp. Motor Area. In the Parietal region: 13) Paracentral Lobe, 14) Postcentral, 15) Parietal Sup., 16) Parietal Inf., 17) Supramarginal, 18) Angular. In the Occipital region: 19) Precuneus, 20) Cuneus, 21) Occipital Sup., 22) Occipital Mid., 23) Occipital Inf., 24) Lingual. In the Temporal region: 25) Temporal Sup., 26) Temporal Pole Sup., 27) Temporal Mid., 28) Temporal Pole Mid., 29) Temporal Inf, 30) Fusiform, 31) Parahippocampal. The Cerebellum, divided in: 32) Cerebelum Crus 1, 33) Cerebelum 3, 34) Cerebelum 4-5, 35) Cerebelum 6, 36) Cerebelum 7b, 37) Cerebelum 8, 38) Cerebelum 9, 39) Cerebelum 10. And additionally, the 40) Medulla, 41) Brain Stem and 42) Insula.}
	\label{fig:regionsCort}
\end{figure*}

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{Graphics/ch6/06-regions_subcortical}
	
	\caption[SBM mapping of some subcortical regions and organs.]{\ac{SBM} mapping of of some important subcortical regions and organs. We observe the following subcortical structures: 1) Caudate Nucleus, 2) Olfactory Bulb, 3) Rolandic Operculum, 4) Heschl's gyri, 5) Putamen, 6) Globus Pallidus, 7) Amygdala, 8) Hippocampus, 9) Thalamus, 10) Lingual, 11) Vermis 4-5, 12) Vermis 7, 13) Vermis 9, 14) Vermis 1-2, 15) Cingulate Gyrus, 16) Corpus Callosum}
	\label{fig:regionsSub}
\end{figure*}

\section{Sampling Paths via Hidden Markov Models}
The rectilinear mapping vector used in the original \ac{SBM} \cite{Martinez-Murcia2014225,Martinez-MurciaVRLBP,Martinez-Murcia2015} has some limitations, partially overcome by the \ac{VRLBP} and the layered extension. However, a more flexible sampling could be beneficial for the computation of texture measures. In this section we present the technique used to define minimum intensity change sampling paths via Hidden Markov Models, that was firstly proposed in \cite{Martinez-Murcia2016}. These paths are defined so that the resulting sampled sets contain information about both intensity and structure of the brain. 

% Algoritmo base de extracciÃ³n de puntos
To define the paths, we consider each three-dimensional image as a tuple that contains spatial information in the image range (the coordinates $\mathbf{p} \in \mathbb{I}$) where $\mathbb{I}\subset \mathbb{R}^3$) as well as intensity information ($I(\mathbf{p}) \in \mathbb{R}$). The intensity information will be interpreted as a sampling of the underlying tissue density, and therefore, an estimation of the probability of finding tissue in each position. 

Following the notation of the \ac{VBM} defined in Section~\ref{sec:mapping}, we formulate a 3D path tracing algorithm that defines a curvilinear mapping set of positions $\mathbb{P}_{\theta,\varphi}$ directly linked to each direction $(\theta,\varphi)$ that is, at the same time, representative of the underlying intensity distribution. We then use both spatial and intensity information to construct the minimum intensity change paths oriented in the direction $(\theta,\varphi)$. Thus, we could note our 3D path in a certain direction as a Markov Model \cite{Chen2008}: 
\begin{equation}
\mathbb{P}_{\theta,\varphi} = \{\mathbf{p}_0, \mathbf{p}_1, \mathbf{p}_2, \dots \mathbf{p}_N\}
\end{equation}
Therefore, our optimum path would be the one that maximizes the probability of the path:
\begin{equation}\label{eq:optimalPath}
\mathbb{P}_{\theta,\varphi}^{opt} = \argmax_{\mathbb{P}_{\theta,\varphi}} \{P(\mathbb{P}_{\theta,\varphi})\}
\end{equation}
or its equivalent, the probability of all the nodes:
\begin{equation}\label{eq:probPath}
P(\mathbb{P}_{\theta,\varphi}) = P(\mathbf{p}_0, \mathbf{p}_1, \mathbf{p}_2, \dots \mathbf{p}_N)
\end{equation}
with $\mathbf{p}_0$ being the origin of the spherical coordinates, and $\mathbf{p}_N$ is the last possible coordinate within $\mathbb{I}$ in the current direction $(\theta,\varphi)$. In this work, we have placed $\mathbf{p}_0$ at the \ac{AC} of the image, although other options, such as setting the origin at the middle point of $\mathbb{I}$ could be considered. This choice is a convention when using the \ac{MNI} coordinates \cite{Evans1993}, sharing conectivity with both hemispheres, therefore allowing the optimal computation of our paths. If we assume a first-order \acf{HMM} for the tracing of the path, the probability of the $i$-th node in the path can be approximated as:
\begin{equation}
P(\mathbf{p}_i | \mathbf{p}_{i-1}, \mathbf{p}_{i-2}, \dots \mathbf{p}_0) \approx P(\mathbf{p}_i|\mathbf{p}_{i-1})
\end{equation}

Using this assumption, Eq.~\ref{eq:probPath} becomes:
\begin{equation}
P(\mathbb{P}_{\theta,\varphi}) = P(\mathbf{p}_0, \mathbf{p}_1, \dots \mathbf{p}_N) = \prod_{i=1}^{N} P(\mathbf{p}_i|\mathbf{p}_{i-1})
\end{equation} 

Using this \ac{HMM} definition, the hidden state of each node will be its intensity $I(\mathbf{p}_i)$. Similarly to the original \ac{SBM}, let $V_{\theta,\varphi} = \{I(\mathbf{p}_0), I(\mathbf{p}_1), \dots I(\mathbf{p}_N)\}$ be the set containing all the intensities at each node of the path. Thank to this, our optimal path (Eq.~\ref{eq:optimalPath}) can be defined as:
\begin{align}
\mathbb{P}_{\theta,\varphi}^{opt} & = \argmax_{\mathbb{P}_{\theta,\varphi}} \{P(\mathbb{P}_{\theta,\varphi}|\mathbf{I})\}\\
P(\mathbb{P}_{\theta,\varphi}|\mathbf{I}) & = P(\mathbf{p}_0, \dots x_N| I(\mathbf{p}_0), \dots I(\mathbf{p}_N))\\
& = \frac{P(I(\mathbf{p}_0), \dots I(\mathbf{p}_N)|\mathbf{p}_0, \dots \mathbf{p}_N)\cdot P(\mathbf{p}_0, \dots \mathbf{p}_N)}{P(I(\mathbf{p}_0), \dots I(\mathbf{p}_N))}\label{eq:final}
\end{align}
where:
\begin{equation}\label{eq:intP}
P(I(\mathbf{p}_0), \dots I(\mathbf{p}_N)|\mathbf{p}_0, \dots \mathbf{p}_N)  = \prod_{i=1}^{N} P (I(\mathbf{p}_i)|\mathbf{p}_i)
\end{equation}
and $P(I(\mathbf{p}_0), \dots I(\mathbf{p}_N))$ is the \textit{a priori} probability of the intensities in the path. We can ignore this term in the optimization process under the assumption that it is constant along the path, which is generally true. 

To avoid computational overload, we will define a restricted set of candidates from which we will derive all the needed probabilities. This set of candidates are defined inside the $L2$-norm support ball $B_{2,r}(\mathbf{p}-\mathbf{p}_{i-1})$ of radius $r$ centred in $\mathbf{p}_{i-1}$, resulting in the candidate set $\mathbb{P}_{\theta,\varphi}^c = \{\mathbf{p}_{c,1}, \mathbf{p}_{c,2}, \dots \mathbf{p}_{c,M} \}$. 

Individual probabilities $P (I(\mathbf{p}_i)|\mathbf{p}_i)$ needed in the computation of Eq.~\ref{eq:intP} can be computed under the assumption of a normally distributed intensity candidate set $V_{\theta,\varphi}^c$ (containing the intensities of the candidate set $\mathbb{P}_{\theta,\varphi}^c$) with mean $I(\mathbf{p}_{i-1})$ and variance $\sigma_c^2$. We will estimate the probability of the i$^{th}$ candidate node $\mathbf{p}_i$ as: 
\begin{equation}\label{eq:intensity}
P(I(\mathbf{p}_i)|\mathbf{p}_i) =\frac{1}{\sqrt{2\pi \sigma_c^2}}\exp\left(-\frac{(I(\mathbf{p}_i)-I(\mathbf{p}_{i-1}))^2}{2\sigma_c^2}\right)
\end{equation}

This support the assumption of minimal intensity change paths, since the $I(\mathbf{p}_i)$ maximizes its probability when similar to $I(\mathbf{p}_{i-1})$. 

Finally, we must restrict the direction of the computed path $\mathbb{P}_{\theta,\varphi}$, to match the definition of the \ac{SBM} framework. We do this by defining the last term $P(\mathbf{p}_0, \dots \mathbf{p}_N)$ in Eq.~\ref{eq:final}, setting an attractor located in the position $\mathbf{p}_N$, the last possible coordinate within $\mathbb{I}$ in the current direction $(\theta,\varphi)$. It should affect the transition probability between states by means of an isotropic \acf{RBF}, defined in Eq.~\ref{eq:rbf}:
\begin{align}\label{eq:rbf}
&P(\mathbf{p}_0, \dots \mathbf{p}_N) = P(\mathbf{p}_i|\mathbf{p}_N)  \\&= \frac{1}{\sqrt{(2\pi)^d|\Sigma|}} \exp\left(-\frac{1}{2}(\mathbf{p}_i-\mathbf{p}_N)\Sigma^{-1}(\mathbf{p}_i-\mathbf{p}_N)\right) 
\end{align}
where $\Sigma$ is the covariance matrix of the \ac{RBF}. For simplicity we will employ an isotropic gaussian kernel, so that $\Sigma$ is a matrix whose diagonal elements constant and equal to the euclidean distance between $\mathbf{p}_i$ and $\mathbf{p}_N$. This way, the attractor conditions the direction of the path, very slightly in the first nodes, and more strongly as it approaches the cortex, leading to a better representation of the underlying structure.  

\subsubsection{Step Size}
This algorithms considers all candidate points $\mathbf{p} \in B_{2,r}(\mathbf{p}-\mathbf{p}_i)$ for each member of the final path $\mathbb{P}_{\theta,\varphi}$. Therefore, instead of a fixed step size, we will define the radius $r$ of the support ball. To avoid computational overload while maintaining good results, we will set $r=3$, which yields approximately $200$ candidate points per iteration. 

\subsubsection{Stop Condition}
The image $\mathbb{I}$ not only contains information about the structure of the brain, but also many empty space. If the attractor is located at the last point $ \mathbf{p} \in \mathbb{I}$, we expect the resulting path to reach that point. However, what we are really interested on is the brain itself, so we define a stop condition that considers that the path is finished once it reaches the last voxel inside the brain. To do so, we use an intensity threshold. 

This threshold is calculated under the entropic thresholding, as in \cite{Yen1995}. If we note $G_m \equiv \{I_0, I_1, ... I_m\} $ the set containing all intensity levels in the image $\mathbf{I}$ (a vectorized image of length $m$), we can compute a histogram that characterizes the observed frequencies. From these frequencies we can derive the observed probability of the different grey levels. The entropic thresholding defines two distributions after normalization: 
\begin{align}
& A \equiv \left\{\frac{p_0}{P(I_{s})}, \frac{p_1}{P(I_{s})}, \dots, \frac{p_{s-1}}{P(I_{s})} \right\}\\
& B \equiv \left\{\frac{p_{s}}{1-P(I_{s})}, \frac{p_{s+1}}{1-P(I_{s})}, \dots, \frac{p_m}{1-P(I_{s})} \right\}
\end{align}
where $P(I_s) = \sum_{i}^{s}p_{I_i}$ is the cumulative density function for the $s$-th grey level. The algorithm is called entropic thresholding because we choose the threshold $I_{th}=I_s$ so that the total amount of information provided by $A$ and $B$ (which we can consider the foreground and background of the image) is maximized. Therefore, we can define the total information provided by choosing the $s$-th grey level as: 
\begin{align}
TE(s) & = E_A(s) + E_B(s) \\
& = -\sum_{i=0}^{s-1}\left(\frac{p_i}{P(I_s)}\right)\log\left(\frac{p_i}{P(I_s)}\right) \\
& - \sum_{i=s}^{m-1}\left(\frac{p_i}{1-P(I_s)}\right)\log\left(\frac{p_i}{1-P(I_s)}\right)
\end{align}

The $s$ that maximizes that latter equation is the grey level that we choose as threshold. 

A summary of our \ac{HMM}-based path tracing method is shown in Algorithm~\ref{alg:hmmPath}. In Figure~\ref{fig:cuts} we show all paths computed in all directions $(\theta,\varphi)$ for $0^o<\varphi<360^o$ and $0^o<\theta<180^o$ at an interval of $1^o$. 

\begin{algorithm*}
	\SetKwData{CandInt}{candInt}
	\SetKwData{PathList}{pathList}
	\SetKwInOut{Input}{input}
	\SetKwInOut{Output}{output}
	\Input{MRI Brain Image $I$ of size $U\times V\times W$, $\mathbf{p}_0$}
	\Output{List of nodes in the optimum path $\mathbb{P}_{\theta,\varphi}^{opt}$}
	\BlankLine
	Compute the $I_{th} = I_s$ where $s$ maximizes $TE(s)$\;
	Set $\mathbf{p}_0$ to the AC\;
	%\For{$\varphi\leftarrow -180$ \KwTo $180$}{
	%	\For{$\theta\leftarrow -90$ \KwTo $90$}{
	Compute the attractor position $\mathbf{p}_N$ in the direction $(\varphi, \theta)$\;
	$\mathbf{p}_i \leftarrow \mathbf{p}_0$\;
	\While{$(i<\text{IterLimit})$ \& $(I(\mathbf{p}_i)>I_{th})$ \& ($\mathbf{p}_i \in \mathbb{I}$)}{
		Get the node candidates $\mathbb{P}_{\theta,\varphi}^c = \{\mathbf{p}_{c,1}, \mathbf{p}_{c,2}, \dots \mathbf{p}_{c,M}\}$ where $\mathbf{p}_{c,m} \in B_{2,r}(\mathbf{p}_{c,m}-\mathbf{p}_i)$\;
		Get the intensities of the candidates $I(\mathbf{p}_c) \quad \forall \mathbf{p}_c \in \mathbb{P}_{\theta,\varphi}^c$\;
		\textbf{foreach} $\mathbf{p}_c \in \mathbb{P}_{\theta,\varphi}^c${
			compute $P(\mathbf{p}_c|\mathbf{p}_N)$ and $P(I(\mathbf{p}_c)|\mathbf{p}_i)$  \;
		}
		$\mathbf{p}_{i+1} = \argmax_{\mathbf{p}_c} [P(I(\mathbf{p}_c)|\mathbf{p}_i)\cdot P(\mathbf{p}_c|\mathbf{p}_N)]$\;
		$i=i+1$\;
	}
	$\mathbb{P}_{\theta,\varphi}^{opt}\leftarrow \{\mathbf{p}_0, \mathbf{p}_1, \dots \mathbf{p}_N\}$\; 
	%	}
	%}
	
	\caption[\acs{HMM}-based Path Creation]{\ac{HMM}-based Path Creation}\label{alg:hmmPath}
\end{algorithm*}\DecMargin{1em}


\begin{figure}
	\begin{center}
		\includegraphics[width=0.7\textwidth]{Graphics/ch6/cuts}
		\caption[Set of \acs{HMM} based paths over the MRI DARTEL template.]{Set of \ac{HMM} based paths over the MRI DARTEL template.}
		\label{fig:cuts}
	\end{center}
\end{figure}


% Con o sin suavizado
\subsection{Radial Texture Features}\label{sec:rtextfeat}
The paths $\mathbb{P}_{\theta,\varphi}$ proposed above could theoretically be used as a feature selection tool to extract the set of intensities $V_{\theta,\varphi}$ as in the standard \ac{SBM}. However, since these new paths contain geometric information, they encode the internal structure, which is itself an additional feature. This encoding could be used to characterize the texture in the neighbourhood of $\mathbb{P}_{\theta,\varphi}$. 

In \cite{Martinez-MurciaVRLBP} a helical sampling was proposed to define the neighbourhood of the mapping vector $\mathbf{v}_{\theta,\varphi}$. Due to the topology of the \ac{HMM} pahts, that is an approach that could not work. Conversely, we propose a modification of the \ac{GLCM} (see Section~\ref{sec:haralick}) that instead of computing the texture in a given direction, characterizes it along the defined \ac{HMM} paths. 

This is basically a node-wise \ac{GLCM}, in which the number of grey-level transitions between adjacent nodes, which we could note as $\mathbf{p}_i$ and $\mathbf{p}_{i+1}$, is stored along the whole path $\mathbb{P}_{\theta,\varphi} = \{\mathbf{p}_0, \mathbf{p}_1 \dots \mathbf{p}_N\}$. Mathematically, the computation of the GLCM in each point in the path will be: 
\begin{equation}\label{eq:glcm}
\mathbf{C}_{\Delta_n}(i,j) = \sum_{n=0}^{N-1}
\begin{cases}
1 & I(\mathbf{p}_n) = i, I(\mathbf{p}_{n+1})=j\\
0 & otherwise
\end{cases}
\end{equation}
where the offset is different for each pair of nodes $\Delta_i=\mathbf{p}_{i+1}-\mathbf{p}_i$. 

The definition in Eq.~\ref{eq:glcm} computes the values at each node, without considering the neighbourhood. We can generalize it to include the surrounding vicinity of the $i$-th node $\mathbf{p}_i$ in the \ac{HMM} path, which we have noted as the set $\mathbb{X}_i$. Under this generalization, equation~\ref{eq:glcm} becomes: 
\begin{equation}\label{eq:glcmGen}
\mathbf{C}(i,j) = \sum_{n=0}^{N-1} \sum_{\mathbf{p} \in \mathbb{X}_i}
\begin{cases}
1 & I(\mathbf{p}) = i, I(\mathbf{p}+\Delta_n)=j\\
0 & otherwise
\end{cases}
\end{equation}

Once the \ac{GLCM} is computed, we can extract a variety of texture descriptors, as defined in Section~\ref{sec:haralickFeatures}. Specifically, in this work, we will use the aforementioned Energy (eq.~\ref{eq:energy}), Entropy (eq.~\ref{eq:entropy}), Correlation (eq.~\ref{eq:correlation}), Contrast (eq.~\ref{eq:contrastHar}) and Homogeneity (eq.~\ref{eq:homogeneity}), along with other texture features proposed in the original Haralick's article \cite{Haralick73} as well as in \cite{soh1999texture} and \cite{clausi2002analysis}. These are Dissimilarity\cite{soh1999texture} (eq.~\ref{eq:dissimilarity}), Difference Variance\cite{Haralick73} (D. Variance, eq~\ref{eq:dvar}), Difference Entropy\cite{Haralick73} (D. Entropy, eq~\ref{eq:dent}), Inverse Difference Normalized\cite{clausi2002analysis} (IDN, eq~\ref{eq:idn}) and Inverse Difference Moment Normalized\cite{clausi2002analysis} (IDMN, eq.~\ref{eq:idmn}). 

\begin{align}\label{eq:dissimilarity}
\text{Dissimilarity} & = \sum_i\sum_j\{|i-j|\mathbf{P}(i,j)\}\\\label{eq:dvar}
\text{D. Variance} &=  \text{VAR}\left\lbrace\sum_{|i-j|=k}\mathbf{P}(i,j)\right\rbrace\\\label{eq:dent}
\text{D. Entropy} &= -\sum\limits_{k=0}^{N_g-1} \sum_{|i-j|=k}\mathbf{P}(i,j) \log \left\lbrace \sum_{|i-j|=k}\mathbf{P}(i,j)\right\rbrace \\\label{eq:idn}
\text{IDN} &= \sum_i\sum_j \frac{\mathbf{P}(i,j)}{1+|i-j|/N}\\ \label{eq:idmn}
\text{IDMN} &= \sum_i\sum_j \frac{\mathbf{P}(i,j)}{i+(j-j)^2/N^2}
\end{align}

\subsection{Experiments}
In this chapter, we have proposed a completely new framework for extracting features and visualizing structural \ac{MRI} images from the ADNI-MRI database. To evaluate them, we will combine statistical significance assessment and classification analysis. For this purpose, we propose the following experiments: 
\begin{itemize}
	\item Experiment 1: assessment of the original \ac{SBM} maps and the \ac{VRLBP} over segmented \ac{GM} and \ac{WM} images. We will provide a statistical significance analysis and a classification analysis under the \ac{AD} vs \ac{CTL} scenario of the six proposed maps. 
	\item Experiment 2: assessment of the layered extension of the \ac{SBM} over segmented \ac{GM} and \ac{WM} images. That way, we want to prove if dividing the sampling set, and thus, increasing the depth resolution of the system affects the overall performance of our system. We will provide statistical significance analysis and classification analysis under the \ac{AD} vs \ac{CTL} scenario . 
	\item Experiment 3: evaluation of the \ac{HMM} based paths on simulated datasets, to demonstrate the ability of this algorithm to adapt to different intensity distributions. 
	\item Experiment 4: evaluation of the \ac{HMM} based paths on a real \ac{MRI} dataset, by taking the different paths as feature selectors, and evaluating the performance obtained by each individual paths, and a combination of them. We provide a classification analysis of the selected features under the \ac{AD} vs \ac{CTL} scenario.
	\item Experiment 5: evaluation of the texture maps derived from the \ac{HMM} based paths on the T1-weighted \ac{MRI} dataset, under a classification analysis of \ac{AD} vs \ac{CTL} subjects. 
\end{itemize}

In te first three experiments, we will used segmented \ac{GM} and \ac{WM} maps, where in experiments 5 and 6, we will use raw, T1-weighted images. The classification analysis is performed by using a linear \ac{SVC} for classifying, and 10-fold cross validation strategy (see Section~\ref{sec:validation} for more details). For estimating statistical significance, we use the two-sample $t$-test defined in Section~\ref{sec:ttestEq}. 


\section{Results}

\subsection{Experiment 1: Original and VRLBP Spherical Brain Mapping}
First, with experiment 1, we test the original and \ac{VRLBP} \ac{SBM} maps, by means of significance and classification analysis. To start with, we provide the significance maps computed under the \ac{AD} vs \ac{CTL} scenario in the six original \ac{SBM} measures (surface, thickness, number of folds, average, entropy and kurtosis) in  Figure~\ref{fig:tmaps}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/07-tmaps}
	\caption[\acs{SBM} t-maps under the \acs{AD} vs \acs{CTL} for \acs{GM} and \acs{WM} images.]{$t$-maps to assess the regions with a higher statistical relevance in the \acs{AD} vs \acs{CTL} paradigm, for each \ac{SBM} measure and using \ac{GM} and \ac{WM} maps. }
	\label{fig:tmaps}
\end{figure*}

For $p<0.05$, in the database subset of the ADNI-MRI, the signifcance threshold can be established at $|t|>1.96$. This means that, in Figure~\ref{fig:tmaps}, the most relevant differences between classes can be found at the areas coloured in dark red (positive, \ac{CTL} subjects have a higher measure) and dark blue (negative, \ac{AD} subjects have a higher measure). For the anatomic structures, we refer to the anatomical reference presented in Section~\ref{sec:anatomical}. 

We first note that the surface measure, tested in both \ac{GM} and \ac{WM} maps, does not look relevant. Very few significant pixels are scattered throughout the image, although with a slightly higher concentration in the areas corresponding to the temporal lobe. 

In the remaining \ac{GM} maps, we observe similar behaviours, with higher absolute $t$-values located in the frontal, occipital and parietal lobes. But again, the most significant areas can be found at the temporal lobe. It is more obvious in the average and entropy measures, but can also be found at the thickness, or negatively in the number of folds and kurtosis maps. This points to the well kown fact that most of the neurodegeneration in \ac{GM} occurs within the structures that are mapped to these directions, including mid temporal lobe, amygdala, hippocampus or parahippocampal lobe, considered a strong indicator in the NINCDS-ADRDA criteria \cite{Dubois2007}. Other \ac{GM} structures such as the caudate nucleus and putamen also appear with significant $t$ values, especially in the entropy and kurtosis maps (with negative $t$) \cite{Pievani2013}. 

In the \ac{WM}, the levels of significance achieved are smaller than in the \ac{GM}, but still high. We see the higher levels of number of folds and thickness located in the vicinity of those obtained for \ac{GM}, but in negative. For the average, entropy and kurtosis measures, we observe a different behaviours. These maps present large areas of negative $t$-values located in the Caudate Nucleus, Globus Pallidus and Putamen. Areas around the posterior cingulate gyrus and the adjacent precuneus also present reduced $t$ values, which could be related to cell loss, as suggested in \cite{Baron2001}.

\begin{figure*}[htp]
	\centering
	\includegraphics[width=\textwidth]{Graphics/ch6/09-tmaps_vrlbp}
	\caption{Maps that present the level of the $t$ statistic in the \ac{AD} vs. \ac{CTL} paradigm, for the VRLBP projections mapping over a) \ac{GM} and b) \ac{WM}. }
	\label{fig:tmapvrlbp}
\end{figure*}

Finally, we take a look at the statistical significance of the \ac{VRLBP} maps. In Figure~\ref{fig:tmapvrlbp}, we can observe that most of the image features small $t$ values, however there are small areas that contain higher significance. These areas correspond to the temporal lobe, amygdala and hippocampus (in the \ac{GM} maps) and smaller regions located at the limits between the hippocampus and amygdala (in \ac{WM}).

Now, we perform a classification analysis of the images. To this purpose, we will use the computed $t$-maps to select the most relevant pixels in the \ac{SBM} maps, which will be used to train and test a \ac{SVC}. The performance results for the six original measures and the \ac{VRLBP} approach, including the percentage of selected pixels (perc.), can be found at Table~\ref{tab:perfProj}. 

\begin{table*}[htp]
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xcccc}
		\tableheadline{Approach} & \tableheadline{Perc.} & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity}\\
		\midrule
		Surface (\ac{GM}) & $0.100$ & $0.638 \pm 0.006$ & $0.660 \pm 0.030$ & $0.616 \pm 0.024$ \\
		Surface (\ac{WM}) & $0.100$ & $0.672 \pm 0.007$ & $0.692 \pm 0.018$ & $0.652 \pm 0.018$ \\
		\midrule
		Thickness (\ac{GM})  & $0.725$ & $0.781 \pm 0.007$ & $0.811 \pm 0.011$ & $0.751 \pm 0.017$ \\
		Thickness (\ac{WM}) & $0.925$ & $0.758 \pm 0.009$ & $0.773 \pm 0.017$ & $0.744 \pm 0.011$ \\
		\midrule
		Num.Fold (\ac{GM}) & $0.600$ & $0.749 \pm 0.013$ & $0.782 \pm 0.019$ & $0.716 \pm 0.013$ \\
		Num.Fold (\ac{WM}) & $0.500$ & $0.757 \pm 0.005$ & $0.745 \pm 0.006$ & $0.768 \pm 0.009$ \\
		\midrule
		Average (\ac{GM}) & $0.575$ & $0.879 \pm 0.005$ & $0.897 \pm 0.006$ & $0.861 \pm 0.006$ \\
		Average (\ac{WM}) & $0.150$ & $0.800 \pm 0.011$ & $0.802 \pm 0.013$ & $0.798 \pm 0.009$ \\
		\midrule
		Entropy (\ac{GM}) & $0.825$ & $0.846 \pm 0.008$ & $0.842 \pm 0.009$ & $0.849 \pm 0.011$ \\
		Entropy (\ac{WM}) & $0.525$ & $0.796 \pm 0.006$ & $0.811 \pm 0.009$ & $0.781 \pm 0.009$ \\
		\midrule
		Kurtosis (\ac{GM}) & $1.000$ & $0.753 \pm 0.007$ & $0.801 \pm 0.011$ & $0.704 \pm 0.015$ \\
		Kurtosis (\ac{WM}) & $0.175$ & $0.697 \pm 0.008$ & $0.702 \pm 0.018$ & $0.693 \pm 0.009$ \\
		\midrule
		VRLBP (\ac{GM}) & $0.200$ & $0.903 \pm 0.010$ & $0.890 \pm 0.012$ & $0.916 \pm 0.018$ \\
		VRLBP (\ac{WM}) & $0.150$ & $0.909 \pm 0.014$ & $0.899 \pm 0.028$ & $0.919 \pm 0.018$ \\
		\bottomrule
	\end{tabularx}
	\caption{Performance values (Average $\pm$ Standard Deviation) for the different \ac{SBM} approaches.}
	\label{tab:perfProj}
\end{table*}

We can see a general trend in which the statistical measures (average, entropy and kurtosis) clearly outperform the morphological ones (surface, thickness and number of folds), although the tissue thickness is the best performing of these, as it could be expected. For \ac{GM} maps, average ($0.879 \pm 0.005$) and entropy ($0.846 \pm 0.008$) achieve the best perforance, followed by thickness ($0.781 \pm 0.007$), kurtosis ($0.753 \pm 0.019$), and finally, the number of folds ($0.749 \pm 0.013$) and surface ($0.638 \pm 0.006$). These results match what we presented previously with the statistical maps, in which the surface contained the less significant measures. 

As for the performance of the \ac{SBM} measures based on \ac{WM} maps, the rank is very similar to that obtained for \ac{GM}. Again, average ($0.800 \pm 0.011$) and entropy ($0.796 \pm 0.006$) are the best performing features among the original measures. They are followed by thickness and the number of folds, with respectively $0.758 \pm 0.009$ and $0.757 \pm 0.005$. Finally, the kurtosis and the surface are the less discriminant measures again, with $0.697 \pm 0.008$ and $0.672 \pm 0.007$. All these measures are outperformed by the \ac{VRLBP} approach, which achieves more than 90\% accuracy in both \ac{GM} and \ac{WM}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/GMperformanceComp}\\
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/WMperformanceComp}
	\caption{Performance for the different \ac{SBM} approaches over the: a) Grey Matter and b) White Matter.}
	\label{fig:figureGM}
\end{figure*}

In Figure~\ref{fig:figureGM} we explore the evolution of the performance as the number of selected pixels varies. Very small differences in the accuracy exist for most measures, and so, we can consider that the performance of the \ac{SBM}, once that a few thousand significant pixels (a 10\% of $181\times361=65341$) have been selected, the system performs well independently of that number. That is, however, not the case of the surface approach, and more remarkably, of the \ac{VRLBP}. In this latter case, for both tissues, the performance is high in the first 40\% of selected voxels, but after that, it dramatically decreases down to less than 70\% accuracy. 

\subsection{Experiment 2: Layered Extension}
In Experiment 2, we have assessed how the performance of our \ac{SBM} varies when adding different layers, which could theoretically improve the accuracy of the \ac{SBM} representation. First, we will take a look at the performance achieved by this extension on all six original \ac{SBM} maps, using 4 layers and different $t$-thresholds (2, 4, 8 and 10). This is presented at Figure~\ref{fig:layeredPerf}. 

\begin{figure*}[htp]
	\centering
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/layerPerfGM}\\
	\includegraphics[width=0.9\textwidth]{Graphics/ch6/layerPerfWM}
	
	\caption[Performance of the four-layered mappings.]{Performance for the different four-layered mappings over the: a) Grey Matter and b) White Matter at different levels of statistical significance.}
	\label{fig:layeredPerf}
\end{figure*}

The first thing that we can observe is that for \ac{GM} maps, the better performance is achieved within the second and third layers, and only for the second layer in the case of \ac{WM}. In almost all cases, the average performance achieves higher accuracy than any other \ac{SBM} measure, closely followed by entropy. It also tells us that, with less restrictive $t$-thresholds, the performance generally decreases, and the best values are between 2 and 4. 

Performing a significance analysis on the 4 layer extension of the 7 proposed \ac{SBM} maps over the \ac{GM} and \ac{WM} images could be infeasible for this thesis, therefore we will only provide $t$-maps of the best performing measure: the average on the \ac{GM} and \ac{WM} tissues. The significance assessing of this case is found at Figure~\ref{fig:tmaplayered}.

\begin{figure*}[htp]
	\centering
	\includegraphics[width=\textwidth]{Graphics/ch6/08-Tmap4LayAverage}
	\caption{$t$-maps that present the level of statistical relevance in the AD vs. NC paradigm, for a four-layered average mapping over a) \ac{GM} and b) \ac{WM}. }
	\label{fig:tmaplayered}
\end{figure*} 

In \ac{GM}, the most obvious changes are located in layers 2 and 3, specifically at the hippocampus, parahippocampal lobe and amygdala (layer 2), and the temporal lobe (layer 3), where the values achieved by \ac{CTL} subjects are much higher than those found in \ac{AD}. This could reveal atrophy in these organs, as it has been reported in the literature \cite{Dubois2007,Pievani2013} and will be discussed later. For \ac{WM}, we obtain large negative $t$-values in areas occupied by the rolandic operculum, heschl's gyri, putamen and globus pallidus, with positive values in parts of the hippocampus, and parts of the temporal lobe. Nevertheless, the most significant differences can be located in layer 1, at the borders between ventricles and thalamus, and the cuneus, precuneus and posterior cingulate gyrus, which have been reported in \cite{Baron2001}.
% DONE


\subsection{Experiment 4: HMM on Synthetic Datasets}
A demonstration of the ability of our \ac{HMM} path tracing algorithm can be found in Figures~\ref{fig:gaussian} and \ref{fig:spire}. In Fig.~\ref{fig:gaussian}, the path tracing algorithm has been tested over a synthesized gaussian mixture probability density function using four isotropic gaussian kernels. The initial point was located at $\mathbf{p}_0 = (120,20)$ and the attractor at $\mathbf{p}_N = (20, 60)$. The resulting path maximizes both the orientation of the path (towards $\mathbf{p}_N$) and the minimum change in the intensity values, which is specially visible in the last nodes of the path, where it approaches $\mathbf{p}_N$ surrounding the nearby kernel. In this case, the chosen L2-norm of the support ball has been $r=3$. 
\begin{figure}
	\begin{center}
		\includegraphics[width=1.5in]{Graphics/ch6/gaussian}
		\caption{Path traced over a gaussian mixture distribution of 4 isotropic gaussian kernels.}
		\label{fig:gaussian}
	\end{center}
\end{figure}

The algorithm has been tested on a three-dimensional, helix-shaped point distribution as well (Fig.~\ref{fig:spire}). The tracing algorithm needs per-voxel intensity (or probability) values, therefore we have estimated the probability distribution of the points as the number of points within each voxel over the total number of points. Using $\mathbf{p}_0$ as the point with minimum $z$ coordinate in the data distribution and $\mathbf{p}_N$ the one with maximum $z$, the resulting path follows the data distribution consistently until it reaches the attractor. 
\begin{figure}
	\begin{center}
		\includegraphics[width=1.5in]{Graphics/ch6/spire}
		\caption{\ac{HMM} path computed inside a density distribution defined by an helix.}
		\label{fig:spire}
	\end{center}
\end{figure}

Finally, we have tested the algorithm on a real world example, using a digital elevation model (DEM) of the Iberian Peninsula, generated by the LANDSAT SRTM30+ mission (see Fig.~\ref{fig:spainmap}). We have tested a multiple path tracing by establishing sequentially $\mathbf{p}_0$ and $\mathbf{p}_N$ in ten cities. The resulting paths optimize both the distance and height variation, as well as resembling -in most cases- the roads that connect these cities in the real world. Given the dimensions of the image, in this case, the L2-norm of the support ball has been set to $r=30$. 

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.7\textwidth]{Graphics/ch6/spain.pdf}
	\caption{Simulation of the \ac{HMM}-based path tracing over an Iberian Peninsula height map, interconecting different cities.}
	\label{fig:spainmap}
\end{figure}


\subsection{Experiment 5: Feature Selection using HMM Paths}

In this section, we present the results of the first experiment involving paths in MRI. To do so, we define a set of canonical paths that are computed on the DARTEL template. These DARTEL paths model the anatomy of a normal subject to whom all other images have been registered. This means that we have fixed the location of the nodes to the structural information of the template, and by extension, to the general anatomy of all images in the database. Therefore, we can characterize the structural differences by the intensity distribution --in other words, the tissue density--  of the voxels at the path nodes. Comparing the intensity distribution found in controls to the one found in AD affected subjects is thus the first logical step to measure how these paths can distinguish the different classes.

To test the algorithm we use the $180\times360=64800$ DARTEL paths computed in each spatial direction $(\theta,\varphi)$, with $\varphi\in[0,360]$ and $\theta\in[-90,90]$, to select the intensities in the voxels that are placed at the nodes. The amount of voxels selected ranges from 2 to several dozens. The set of selected intensities are used as features to train and test a SVM classifier. The accuracy reached by each path (using the aforementioned cross-validation strategy) is presented as colour information in Figure~\ref{fig:accuracyMap}. The higher accuracy obtained using only one path is $0.8028\pm0.0873$, and corresponds to the light green paths that cross the temporal lobe. 

\begin{figure}
	\begin{center}
		\includegraphics[width=\columnwidth]{Graphics/ch6/accuracyPaths2}
		\caption{DARTEL paths computed in each direction ($\theta,\varphi$). Each path's colour represent the accuracy in a differential diagnosis. Only one in every five paths are shown for clarity purposes.}
		\label{fig:accuracyMap}
	\end{center}
\end{figure}

It is interesting to question if the performance of this differential diagnosis could be improved using the information contained in more than one path at a time. To this end, we first take the higher accuracy ($\text{accuracy} \ge0.7$) paths according to the aforementioned performance and select all voxels located in the nodes of these paths. Additionally, we use a $t$-test over the set of voxels selected by these paths, to further reduce the set to those voxels that have significant ($p<0.05$) $t$-values ($|t|>1.96$). The performance values for the experiment involving all voxels in the paths (first row) and the one that uses only those significant voxels (second row) are presented in Table~\ref{tab:acc}. 

\begin{table}
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xccc}
		\tableheadline{Side} & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity} \\ \midrule
		Both & $0.806 \pm 0.069 $ & $0.733 \pm 0.073$ & $0.878 \pm 0.097$\\
		Left & $0.769 \pm 0.035 $ & $0.717 \pm 0.061$ & $0.822 \pm 0.057$\\
		Right & $0.792 \pm 0.080 $ & $0.706 \pm 0.120$ & $0.878 \pm 0.101$\\
		\midrule 
		Both & $0.828 \pm 0.054 $ & $0.794 \pm 0.095$ & $0.861 \pm 0.039$\\
		Left & $0.733 \pm 0.037 $ & $0.694 \pm 0.099$ & $0.772 \pm 0.124$\\
		Right & $0.781 \pm 0.085 $ & $0.711 \pm 0.122$ & $0.850 \pm 0.083$\\
		\bottomrule
	\end{tabularx}
	\caption{Performance values ($\pm$SD) for the selected paths as features, and using $t$-test to select the voxels.} 
	\label{tab:acc}
\end{table}

Finally, we mimic the procedure followed in the \ac{SBM} article\cite{Martinez-Murcia2015}. That is, we first compute the average, variance, entropy and kurtosis maps of each brain, but instead of using rectilinear paths, we use the DARTEL paths. Afterwards, all the features contained in these maps are used as an input to the SVM classifier. The performance results are shown in Table~\ref{tab:sbm_perf}. 

\begin{table}
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xccc}
		\tableheadline{Feature} & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity} \\ \midrule
		Average & $0.594 \pm 0.062 $ & $0.661 \pm 0.121$ & $0.528 \pm 0.106$\\
		Variance & $0.750 \pm 0.064 $ & $0.633 \pm 0.131$ & $0.867 \pm 0.102$\\
		Entropy & $0.603 \pm 0.069 $ & $0.661 \pm 0.071$ & $0.544 \pm 0.125$\\
		Kurtosis & $0.756 \pm 0.105 $ & $0.733 \pm 0.165$ & $0.778 \pm 0.150$\\
		\bottomrule
	\end{tabularx}
	\caption{Performance values ($\pm$SD) for each of the measures used in the \ac{SBM} article.} 
	\label{tab:sbm_perf}
\end{table}

\subsection{Experiment 6: Texture SBM Maps based on HMM Paths}
The second experiment is intended to extract texture features from the DARTEL paths. With this approach, we obtain one single value per texture feature and path in the subjects, values that intrinsically contain information from their location in the path, in contrast to standard \ac{SBM} measures. In the end, each subject will be characterized by a 2D, $361\times181$ array of scalars, one for each texture feature applied to the paths. Performance values for the nine texture features maps from Section~\ref{sec:rtextfeat} are presented in Table~\ref{tab:texture}.

\begin{table*}
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xccc}
		\tableheadline{Feature} & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity} \\ \midrule
		Contrast & $0.733 \pm 0.060 $ & $0.689 \pm 0.126$ & $0.778 \pm 0.105$\\
		Correlation & $0.672 \pm 0.068 $ & $0.672 \pm 0.112$ & $0.672 \pm 0.100$\\
		Dissimilarity & $0.711 \pm 0.085 $ & $0.678 \pm 0.110$ & $0.744 \pm 0.102$\\
		Energy & $0.689 \pm 0.061 $ & $0.700 \pm 0.115$ & $0.678 \pm 0.073$\\
		Entropy & $0.675 \pm 0.101 $ & $0.672 \pm 0.115$ & $0.678 \pm 0.159$\\
		Homogeneity & $0.697 \pm 0.058 $ & $0.700 \pm 0.115$ & $0.694 \pm 0.106$\\
		Difference Variance & $0.736 \pm 0.070 $ & $0.683 \pm 0.098$ & $0.789 \pm 0.090$\\
		Difference Entropy & $0.725 \pm 0.122 $ & $0.683 \pm 0.176$ & $0.767 \pm 0.114$\\
		IDN & $0.719 \pm 0.065 $ & $0.683 \pm 0.108$ & $0.756 \pm 0.105$\\
		IDMN & $0.717 \pm 0.076 $ & $0.678 \pm 0.125$ & $0.756 \pm 0.084$\\
		\bottomrule
	\end{tabularx}
	\caption{Performance values ($\pm$SD) for each of the 10 texture features.} \label{tab:texture}
\end{table*}

The higher accuracy obtained by the texture maps is $0.736 \pm 0.070$, corresponding to Difference Variance. The performance values of the different texture features, all obtaining accuracies higher than $65\%$ (most of them above $70\%$) reveal the discrimination abilities of these textures, although these values are not as good as those obtained using the voxel intensities or the \ac{SBM} features. 

% DONE

\subsubsection{Layered Extension}\label{sec:layeredttest}


\subsubsection{VRLBP}\label{sec:vrlbpttest}


\subsection{Classification Analysis}\label{sec:classification}
To obtain comparable performance metrics suitable to analyse the generalization capabilities of \ac{SBM}, in this section a number of classification results are presented. A baseline is established in Section~\ref{sec:baseline} and then the performance of our maps, included the layered extension and VRLBP, is presented in Section~\ref{sec:sbmclass}.

\subsubsection{Baseline - VAF}\label{sec:baseline}
In order to establish a baseline to assess the predictive ability of our maps, we will use the \acf{VAF} paradigm, described in \cite{Stoeckel04}. This approach uses the whole 3D \ac{GM} or \ac{WM} segmented MR images and then uses all voxels of the 3D images as features in the SVM classification, yielding the performance values shown in Table~\ref{tab:perfVAF}. The performance of the \ac{SBM} maps will be compared to these. 

\begin{table*}[htp]
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xccc}
		\tableheadline{Approach}  & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity}\\
		\midrule
		\ac{VAF} (\ac{GM})  & $0.768 \pm 0.011$ & $0.752 \pm 0.016$ & $0.785 \pm 0.016$ \\
		\ac{VAF} (\ac{WM})  & $0.642 \pm 0.009$ & $0.668 \pm 0.012$ & $0.617 \pm 0.013$ \\
		\bottomrule
	\end{tabularx}
	\caption{Performance values (Average $\pm$ Standard Deviation) for the  Voxels as Features approach in both \ac{GM} and \ac{WM} tissues.\label{tab:perfVAF}}
\end{table*}


\section{Discussion}
\subsection{Spherical Brain Mapping}
The structural changes in MR images during the progression of the Al\-zhei\-mer's Disease are widely documented in the bibliography \cite{Misra2009,Baron2001,Pievani2013,Stoeckel04,han2006reliability,Fischl2004}. According to our current knowledge, the neurodegeneration and posterior atrophy occurs mainly in the \ac{GM} tissue, although significant changes are present also in \ac{WM}. 

The mappings defined throughout Sections~\ref{sec:mapping}, \ref{sec:layered} and \ref{sec:vrlbp} account for different properties of the tissues crossed by $\mathbf{v}_{\theta,\varphi}$. As it can be seen in Figure~\ref{fig:performance}, our mappings show in general a higher performance when using the \ac{GM} tissue, which is consistent with the literature. There are some exceptions, however, being the clearest the VRLBP, and, to a lesser extent, the number of folds and surface. The different mappings and their utility will be described in the following paragraphs. 

\begin{figure}[htp]
	\centering
	\includegraphics[width=0.9\columnwidth]{Graphics/ch6/12-performance}
	\caption{Performance at the operation point for the different mappings over the Grey Matter and White Matter, compared with the performance of \ac{VAF}.}
	\label{fig:performance}
\end{figure}

The first three approaches, Surface, Thickness and Number of Folds are easily interpreted, as they intend to represent the surface of the tissue by mapping the distance between the centre of the image and the last voxel, the thickness of the tissue, and a measure of the complexity of the different sulci and gyri. 

Surface and Thickness are highly related to other measures provided by widely-used software. However, as they are related to our more general \ac{SBM} description, their performance is poor, specially in the case of the Surface mapping. As it can be seen in Fig.~\ref{fig:masksGM}, and later in the $t$-maps at Fig.~\ref{fig:tmaps}, the detail of the surface map lacks higher detail, specially due to the superposing gyri and sulci. These superposition occur to a lesser extent in \ac{WM} tissue, and this is probably why this technique obtains higher performance in \ac{WM} than in \ac{GM}. 

As for the case of Thickness, although similar, it gathers much more information than the surface, without achieving, however, the level of detail of the cortical thickness measures provided by Freesurfer \cite{Fischl2004} or other software. Nevertheless, cortical thickness it is a descriptive, widely accepted as a measure of neurodegeneration in Alzheimer's Disease in the literature \cite{han2006reliability,Fischl2004}, and its measures might be relevant for a subsequent analysis. 

Number of Folds, however, is intended to model the complexity of the cerebral cortex, and therefore, it is of far more use in the case of \ac{GM} than in the \ac{WM}. This can be easily checked when looking at the maps obtained for both \ac{GM} and \ac{WM} in Figure~\ref{fig:masksGM}. 

The last three measures described in Section~\ref{sec:mapping} are statistical values that describe the variability of the sampling set $V_{\theta,\varphi}$. It would be reasonable to expect the better performance to be linked to the mapping that better models the tissue atrophy. 

This is the case of the average of these intensities, which can be interpreted as the total amount of tissue, being therefore a good measure of the level of brain atrophy in each direction $(\theta,\varphi)$. The average maps show the best performance of all the measures proposed in Section~\ref{sec:mapping}, and is higher in \ac{GM} than in \ac{WM}. This is consistent with the literature, as atrophy mainly occurs in \ac{GM} tissues. 

Entropy is a more complex statistical concept that comes from information theory, but is usually related to the amount of information, or in other words, the ``randomness'' of a source. In our particular case it could be interpreted as a measure of texture, that is, the grey-level variability in the direction of $\mathbf{v}_{\theta,\varphi}$. These maps perform very similar to the average ones in both \ac{GM} and \ac{WM}, suggesting that the entropy accounts for the tissue density as well. 

The last mapping defined, Kurtosis, is a fourth-order statistic, often interpreted as the peakedness (width of peak) of a probability distribution. In our context, it is related to the sharpness of the changes in the direction of $\mathbf{v}_{\theta,\varphi}$, and thus is related to the number of folds. As in the case of the latter, the Kurtosis performs poorly in both types of tissues, probably because they are measures that are not as directly related to atrophy as other measures such as average, entropy or thickness. 

The last of the single measures proposed in this work is the Volumetric Radial LBP defined in Section~\ref{sec:vrlbp}. It is a measure of the texture not only in the direction of $\mathbf{v}_{\theta,\varphi}$, but also in the neighbourhood of the mapping vector. Therefore, it is not strange that it obtains the best performance of the whole work, yielding accuracy results above $0.9$ for both \ac{GM} and \ac{WM} tissues. 

This could seem counter-intuitive, as the $t$-maps for this technique, presented in Fig.~\ref{fig:tmapvrlbp}, show small regions of high significance, when compared to the measures in Sec.~\ref{sec:mapping}. Yet, despite its size, it performs fairly well with a relatively small amount of data. It is probably due to the nature of VRLBP, and the areas highlighted in Fig.~\ref{fig:tmapvrlbp} probably correspond to the texture changes associated to the loss of tissue in the Hippocampus. 

As for the layered extension, which might seem a powerful method to add detail to the mappings, obtains however similar performance to the methodology above. It seems that the amount of information that can be obtained by each measure does not depend on the number of layers, and accordingly, its benefits are only related to visualization. In this case, best values are obtained in layer 2, which is consistent to the presence of some organs, specially the Hippocampus.  
%%%%%%%%%%%%%%%%%%%%%%%% 

\begin{figure*}[htp]% ROC
	\centering
	\includegraphics[width=0.8\textwidth]{Graphics/ch6/13-ROC}
	
	\caption{ROC curves of the different mappings for the \ac{GM} and \ac{WM} tissues.}
	\label{fig:roc}
\end{figure*}

Finally, in order to have another look at the performance of our mappings, the ROC curves of each type are presented in Figure~\ref{fig:roc}. There we can see how the VRLBP approach outperforms all the other measures, specially in the case of \ac{WM} tissue. In \ac{GM}, Average and Entropy present values really close to VRLBP, as expected. Conversely, the poorest performance is achieved by the Kurtosis and Surface mappings, however the Surface performs better in \ac{WM} than in \ac{GM}. These results confirm the performance values presented in  Table~\ref{tab:perfProj} and Figure~\ref{fig:figureGM}, making our proposed mapping framework a reasonable choice for obtaining both a visual interpretation of otherwise hidden features and a significant dimensionality reduction. 

It is important to note that our Spherical Brain Mapping defines a whole framework that can be easily extended with different sampling strategies. This is the case of the layered extension and the helical sampling in VRLBP, but they are only two examples of what can be done. 
Since our simplest approach implies a computation of a value from a vector of intensities, measures used to describe time-course data could be added to complete and highlight different properties of the tissues. In this context, high-order statistics \cite{Zhou2008}, as well as spectral measures \cite{Locatelli1998} have been successfully applied to analyse electroencephalogram (EEG) signals, and could be therefore applied here to bring different structural properties of the images into focus. 
Additionally, our mapping method is potentially applicable to other imaging modalities, such as PET and SPECT, where the structural information is sometimes lost \cite{IAIllan2010,Ram'irez2009}. Our technique does not need the use of complex co-registering of MRI and functional imaging to locate cerebral structures, as it rely only in their angle and depth. Moreover, in the case of Diffusion Tensor Imaging (DTI), which has proven itself as a good tool for the diagnosis of Alzheimer's Disease \cite{Grana2011,Medina2008}, \ac{SBM} could be modified to replace $\mathbf{v}_{\theta,\varphi}$ with each tract, and subsequently project a given feature, resulting in a summary of the tract's behaviour in a single two-dimensional image. 

			

\subsection{Paths via \ac{HMM}}\label{sec:discussion}
In this work we propose a new path tracing algorithm based on Hidden Markov Models used to trace similar intensity paths inside the brain. The paths are meant to be used as a feature extraction tool in the \ac{SBM} framework either by selecting voxels or computing features. We have performed several experiments to evaluate these approaches in a differential diagnosis of AD using MRI brain images. 

Our paths are defined so that they construct a minimum intensity variation path starting at the AC and oriented in a general direction set by the spherical coordinate pair $(\theta,\varphi)$. As commented before, the AC is the obvious starting point, given its privileged position in the middle of the left and right hemispheres. A different starting point will reveal suboptimal, stopping at disconnected regions such as the ventricles, and yielding incomplete paths. 

The paths adapt to the intensity changes in a certain direction in the brain, modelling grey level connectivity in all spherical directions. Since grey level is directly related to tissue density, we can assume that the outcome follows smooth, same-density paths that start in white matter and progressively transition to grey matter in a specific direction. Therefore, they are not functional connectivity maps like Diffusion Tensor Imaging (DTI), which have been used as well in the diagnosis of AD\cite{Grana2011,Medina2008}. While DTI fibers are the result of a tensor processing over diffusion images that quantify the water molecule motion -in both direction and average magnitude- at the voxel level, our \ac{HMM} paths only characterize grey level connectivity in static MRI images, and are meant to be used for feature selection. 

\begin{figure}
	\begin{center}
		\includegraphics[width=\columnwidth]{Graphics/ch6/radia&structures}
		\caption{Paths that obtain more than 75\% accuracy, and a three-dimensional representation of the structures crossed by them.}
		\label{fig:bestPaths}
	\end{center}
\end{figure}

Our first experiment uses \ac{HMM} paths computed on the DARTEL template to describe how the intensity of the set of voxels corresponding to a certain path can be used as discriminant features in a SVM classifier. The differences in the distribution of intensities between controls and AD affected subjects are used to identify structural changes in AD. Fig.~\ref{fig:bestPaths} depicts the paths that achieved best performance (accuracy higher than $0.75$) in this differential diagnosis, superimposed to some structures rendered from the Automated Anatomical Labeling (AAL) brain atlas\cite{Tzourio-Mazoyer2002}.

The paths that obtained higher accuracy are those that cross structures such as the Hippocampus, Amygdala, Thalamus, Fusiform and Inferior Temporal Gyrus. Particularly, grey matter loss in the Hippocampus has been described in the NINCDS-ADRDA criteria for AD diagnosis\cite{Dubois2007} and is widely accepted\cite{chan2001patterns,Baron2001,Jong2008}. Furthermore, the evidence suggest that atrophy affects the surrounding structures (Amygdala, Parahippocampal and Fusiform Gyrus) as well\cite{chan2001patterns,Baron2001}. Some studies have found significant atrophy in the Thalamus and Putamen in early AD\cite{Jong2008} as well. Generally, in advanced AD, most of the neocortex and grey matter suffer from atrophy\cite{chan2001patterns,Baron2001,Jong2008}, which explains why most of the paths that involve the neocortex in Fig.~\ref{fig:accuracyMap} obtain accuracy rates around $0.7$. 

A number of feature maps have been computed as well. These are the result of applying some of the \ac{SBM} measures to the voxels selected by the \ac{HMM} paths. Variance and kurtosis have been proved as the most discriminative maps (with accuracy higher than $0.7$). This is coherent with the definition of the paths, where the intensity transitions are minimal. Therefore, average would be the less discriminative in this case, being higher order statistics such as variance or more representative of the tissue density distribution of each class. 

Regarding texture analysis, we have again discriminative features (with accuracy that surpass the 70\%) yet not very powerful. This situation might be due to the definition of the paths as minimum intensity variation paths, being the textural changes along the path minimal.  

However the real utility of these texture features could be in its application to longitudinal studies, since textsure can be related to evolution of the disease\cite{sikio2015mr}. It is very convenient to use a scalar to characterize a measure (in our case, texture features) in each direction. The texture obtained in each session can be used to construct a function of neurodegeneration that allows the exploration of the different stages of the disease as the changes in the brain texture along the time within a single patient. 

Table \ref{tab:comparison2} presents some of the best results of our methodology involving \ac{HMM} paths in this order: the performance of a single path and using the selected paths as features (Section~\ref{sec:intensity}), the performance of using projected maps (in this case, variance and kurtosis) like in the \ac{SBM} paper (Section~\ref{sec:intensity}) and the results of computing texture maps using radial GLCM and Haralick Texture Features (Section~\ref{sec:texture}). It is compared with the methods using in the \ac{SBM} paper\cite{Martinez-Murcia2015}, the \ac{SBM}-VRLBP\cite{Martinez-MurciaVRLBP}, the \acf{VAF}\cite{Stoeckel04} algorithm and different approaches used in the ADNI database and involving SVM classifiers such as the LVQ-SVM\cite{Ortiz2013} or Spatial Component Analysis (SCA)\cite{Illan2014}. 

\begin{table*}
	\myfloatalign
	\begin{tabularx}{\textwidth}{Xccc}
			\tableheadline{Feature} & \tableheadline{Accuracy} & \tableheadline{Sensitivity} & \tableheadline{Specificity} \\ \midrule
			Paths & $0.806 \pm 0.069 $ & $0.733 \pm 0.073$ & $0.878 \pm 0.097$\\
			Selected Paths & $0.828 \pm 0.054 $ & $0.794 \pm 0.095$ & $0.861 \pm 0.039$\\
			Variance & $0.750 \pm 0.064 $ & $0.633 \pm 0.131$ & $0.867 \pm 0.102$\\
			Kurtosis & $0.756 \pm 0.105 $ & $0.733 \pm 0.165$ & $0.778 \pm 0.150$\\
			Texture (Difference Variance) & $0.736 \pm 0.070 $ & $0.683 \pm 0.098$ & $0.789 \pm 0.090$\\
			\midrule 
			\ac{VAF}  & $0.768 \pm 0.011$ & $0.752 \pm 0.016$ & $0.785 \pm 0.016$ \\
			\ac{SBM}-average (\ac{GM})  & $0.879 \pm 0.005$ & $0.897 \pm 0.006$ & $0.861 \pm 0.006$ \\
			\ac{SBM}-average (\ac{WM})  & $0.800 \pm 0.011$ & $0.802 \pm 0.013$ & $0.798 \pm 0.009$ \\ 
			\ac{SBM}-VRLBP (\ac{GM})  & $0.903 \pm 0.010$ & $0.890 \pm 0.012$ & $0.916 \pm 0.018$ \\
			\ac{SBM}-VRLBP (\ac{WM}) & $0.909 \pm 0.014$ & $0.899 \pm 0.028$ & $0.919 \pm 0.018$ \\
			LVQ-SVM (\ac{GM}) & $0.869 \pm 0.101$ & $0.822\pm0.120$ & $0.890\pm0.102$ \\ 	
			SCA (\ac{GM}) & $0.880 \pm0.0^* $ & $0.926\pm0.0^* $ & $0.845\pm0.0^*$ \\ 
			SCA (\ac{WM}) & $0.808 \pm 0.0^*$ & $0.817\pm0.0^*$ & $0.800\pm0.0^*$ \\ 	
			\bottomrule
			\multicolumn{4}{l}{$^*$ SCA used leave-one-out cross-validation. SD is 0.}
		\end{tabularx}
		
		\caption{Comparison between our algorithm performance values (best values for selected voxels in all paths and texture features) ($\pm$SD) and other methods in the bibliography} \label{tab:comparison2}
	\end{table*}
	
	
	\ac{VAF} is often used as a baseline when comparing different methodology, as it has been described as a good estimator of the accuracy obtained by means of visual analysis \cite{Stoeckel04}. As we commented before, the raw voxel intensities selected by our DARTEL paths achieve higher accuracy than statistical or texture features, and it is the only strategy that outperforms \ac{VAF}. Texture and statistical features obtain poorer, although still good, performance (around 75\% accuracy). When compared to other methods, the difference is greater, although inside the range of 1 SD. Most of the \ac{SBM} features proposed in \cite{Martinez-Murcia2015} perform better than our DARTEL paths, and the case of \cite{Martinez-MurciaVRLBP} even surpass the barrier of 90\% accuracy. However, there is a significant difference with these approaches, and it is that these measures used segmented \ac{GM} and \ac{WM} images, instead of using the whole MRI. Segmentation, thus, enhances the detection and extraction of features from the images, whereas the tracing of paths over the whole images is a more complex operation. When compared to LVQ-SVM or SCA, the difference in performance is even smaller and still inside the range of 1 SD, which gives us an idea of the ability of our methodology to detect patterns with a significant feature reduction.
	
	Finally, one might argue if a different approach to the path tracing, such as tracing the set of paths in each subject individually might be of use. This strategy would still characterize the individual brain structure; however the way this structure is defined would be different: the spatial location of the nodes and topology of the paths instead of the intensity distribution. Given the time our algorithm takes to model one single MRI (around 2 hours) it can be extraordinarily computationally expensive, although faster than other methodology like DTI fiber tracing or Freesurfer surface extraction. Consequently, it would be an interesting option to explore in future works. 